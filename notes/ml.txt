from google.colab import drive
drive.mount('/content/drive')
import os
os.listdir('/content/drive/MyDrive')
os.listdir('/content/drive/MyDrive/ML_Projects/Weather_Project')

now make it our main folder to work in
os.chdir('/content/drive/MyDrive/ML_Projects/Weather_Project')


import os
folders = [
    'data',
    'data/raw',
    'data/processed',
    'models',
    'notebooks',
    'outputs'
]
for folder in folders:
    os.makedirs(folder, exist_ok=True)
print("Project structure created successfully!")
ğŸ”¹ os.makedirs()
This creates folders.
ğŸ”¹ exist_ok=True
Means:
â€œIf folder already exists, donâ€™t throw error.â€


download data set locally and save it to raw folder


import pandas as pd
df = pd.read_csv("data/raw/Weatherdata.csv")
df.head()

df.describe()
count = how many non missing values
mean = the avg value
std = standered deviation - small - data close to mean,large-data vary a lot
25 - 75 = data are below this value
50 - median

check for missing values - df.isnull().sum()
df = df.dropna() - remove rows with missing values
df.fillna(df.mean(numeric_only=True), inplace=True) - fill missing coz ml cannot hanndle

X = df[['Humidity', 'Pressure (millibars)', 'Wind Speed (km/h)']]
y = df['Temperature (C)']
defining  x and y - x input to get output

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42
)
split data in two parts and 42 to handle randomness

now using linear regression  to train_test_split
from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X_train, y_train) â€œLook at training data and calculate the best weights.â€

Temperature=w1â€‹(Humidity)+w2â€‹(Pressure)+w3â€‹(WindSpeed)+b
- model job is to calculate w with minimum cost

from sklearn.metrics import mean_squared_error, r2_score

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

y_pred = model.predict(X_test)
giving test set to predict



evalute model
from sklearn.metrics import mean_squared_error, r2_score

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
MSE= mean square error , lower better
RÂ² measures:
How much of temperature variation is explained by our features.
1 â†’ Perfect
0 â†’ Useless
Negative â†’ Terrible
Example:
If RÂ² = 0.75
It means:
75% of temperature variation is explained by humidity, pressure, wind speed.

AS MODEL SCORE IS BAD 
coz we dinot considered many features , and date and time
df['Formatted Date'] = pd.to_datetime(df['Formatted Date'])
It converts text like:
2016-01-01 00:00:00
Into a real datetime object.

df['Formatted Date'].dtype
df['Formatted Date'] = pd.to_datetime(df['Formatted Date'], errors='coerce')
invalid values to Nat , so no crashing

extract time features 
df['year'] = df['Formatted Date'].dt.year
df['month'] = df['Formatted Date'].dt.month
df['day'] = df['Formatted Date'].dt.day
df['hour'] = df['Formatted Date'].dt.hour

from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

print("RÂ²:", model.score(X_test, y_test))

| Feature                     | Linear Regression | Random Forest |
| --------------------------- | ----------------- | ------------- |
| Assumes linear relationship | âœ… Yes             | âŒ No          |
| Handles non-linear patterns | âŒ Poor            | âœ… Excellent   |
| Handles feature interaction | âŒ Limited         | âœ… Automatic   |
| Works with complex data     | âŒ Weak            | âœ… Strong      |
| Easy to interpret           | âœ… Very            | âŒ Less        |




saving ur model
import joblib
joblib.dump(model, "models/temperature_model.pkl")


to use model on new data 
model = joblib.load("models/temperature_model.pkl")

This restores the exact same model you saved earlier

You can now use model.predict() on new data